[
  {
    "text": "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance",
    "type": "semantic",
    "chunk_id": "wiki_0_chunk_0",
    "source_doc_id": "wiki_0",
    "source_title": "Machine learning",
    "source": "wikipedia",
    "chunk_index": 0,
    "word_count": 68,
    "char_count": 460,
    "metadata": {
      "original_length": 462,
      "cleaned_length": 462,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals",
    "type": "semantic",
    "chunk_id": "wiki_1_chunk_0",
    "source_doc_id": "wiki_1",
    "source_title": "Artificial intelligence",
    "source": "wikipedia",
    "chunk_index": 0,
    "word_count": 64,
    "char_count": 461,
    "metadata": {
      "original_length": 463,
      "cleaned_length": 463,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and training them to process data The adjective deep refers to the use of multiple layers in the network Methods used can be supervised, semi-supervised or unsupervised",
    "type": "semantic",
    "chunk_id": "wiki_2_chunk_0",
    "source_doc_id": "wiki_2",
    "source_title": "Deep learning",
    "source": "wikipedia",
    "chunk_index": 0,
    "word_count": 64,
    "char_count": 454,
    "metadata": {
      "original_length": 462,
      "cleaned_length": 458,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Natural language processing (NLP) is the processing of natural language information by a computer The study of NLP, a subfield of computer science, is generally associated with artificial intelligence NLP is related to information retrieval, knowledge representation, computational linguistics, and more broadly with linguistics",
    "type": "semantic",
    "chunk_id": "wiki_3_chunk_0",
    "source_doc_id": "wiki_3",
    "source_title": "Natural language processing",
    "source": "wikipedia",
    "chunk_index": 0,
    "word_count": 44,
    "char_count": 328,
    "metadata": {
      "original_length": 331,
      "cleaned_length": 331,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e in the form of decisions Understanding in this context signifies the transformation of visual images into descriptions of the world that make sense to thought processes and can elicit appropriate action",
    "type": "semantic",
    "chunk_id": "wiki_4_chunk_0",
    "source_doc_id": "wiki_4",
    "source_title": "Computer vision",
    "source": "wikipedia",
    "chunk_index": 0,
    "word_count": 62,
    "char_count": 429,
    "metadata": {
      "original_length": 627,
      "cleaned_length": 625,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory",
    "type": "semantic",
    "chunk_id": "wiki_4_chunk_1",
    "source_doc_id": "wiki_4",
    "source_title": "Computer vision",
    "source": "wikipedia",
    "chunk_index": 1,
    "word_count": 28,
    "char_count": 189,
    "metadata": {
      "original_length": 627,
      "cleaned_length": 625,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "In this paper, we propose a training-free framework for vision-and-language navigation (VLN) Existing zero-shot VLN methods are mainly designed for discrete environments or involve unsupervised training in continuous simulator environments, which makes it challenging to generalize and deploy them in real-world scenarios",
    "type": "semantic",
    "chunk_id": "arxiv_0_chunk_0",
    "source_doc_id": "arxiv_0",
    "source_title": "GC-VLN: Instruction as Graph Constraints for Training-free\n  Vision-and-Language Navigation",
    "source": "arxiv",
    "chunk_index": 0,
    "word_count": 42,
    "char_count": 321,
    "metadata": {
      "original_length": 1657,
      "cleaned_length": 1656,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "To achieve a training-free framework in continuous environments, our framework formulates navigation guidance as graph constraint optimization by decomposing instructions into explicit spatial constraints The constraint-driven paradigm decodes spatial semantics through constraint solving, enabling zero-shot adaptation to unseen environments Specifically, we construct a spatial constraint library covering all types of spatial relationship mentioned in VLN instructions",
    "type": "semantic",
    "chunk_id": "arxiv_0_chunk_1",
    "source_doc_id": "arxiv_0",
    "source_title": "GC-VLN: Instruction as Graph Constraints for Training-free\n  Vision-and-Language Navigation",
    "source": "arxiv",
    "chunk_index": 1,
    "word_count": 56,
    "char_count": 471,
    "metadata": {
      "original_length": 1657,
      "cleaned_length": 1656,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "The human instruction is decomposed into a directed acyclic graph, with waypoint nodes, object nodes and edges, which are used as queries to retrieve the library to build the graph constraints The graph constraint optimization is solved by the constraint solver to determine the positions of waypoints, obtaining the robots navigation path and final goal To handle cases of no solution or multiple solutions, we construct a navigation tree and the backtracking mechanism",
    "type": "semantic",
    "chunk_id": "arxiv_0_chunk_2",
    "source_doc_id": "arxiv_0",
    "source_title": "GC-VLN: Instruction as Graph Constraints for Training-free\n  Vision-and-Language Navigation",
    "source": "arxiv",
    "chunk_index": 2,
    "word_count": 73,
    "char_count": 470,
    "metadata": {
      "original_length": 1657,
      "cleaned_length": 1656,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Extensive experiments on standard benchmarks demonstrate significant improvements in success rate and navigation efficiency compared to state-of-the-art zero-shot VLN methods We further conduct real-world experiments to show that our framework can effectively generalize to new environments and instruction sets, paving the way for a more robust and autonomous navigation framework",
    "type": "semantic",
    "chunk_id": "arxiv_0_chunk_3",
    "source_doc_id": "arxiv_0",
    "source_title": "GC-VLN: Instruction as Graph Constraints for Training-free\n  Vision-and-Language Navigation",
    "source": "arxiv",
    "chunk_index": 3,
    "word_count": 50,
    "char_count": 381,
    "metadata": {
      "original_length": 1657,
      "cleaned_length": 1656,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Alzheimers disease is a progressive, neurodegenerative disorder that causes memory loss and cognitive decline While there has been extensive research in applying deep learning models to Alzheimers prediction tasks, these models remain limited by lack of available labeled data, poor generalization across datasets, and inflexibility to varying numbers of input scans and time intervals between scans",
    "type": "semantic",
    "chunk_id": "arxiv_1_chunk_0",
    "source_doc_id": "arxiv_1",
    "source_title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and\n  Adaptability Across Alzheimer's Prediction Tasks and Datasets",
    "source": "arxiv",
    "chunk_index": 0,
    "word_count": 56,
    "char_count": 399,
    "metadata": {
      "original_length": 1342,
      "cleaned_length": 1335,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "In this study, we adapt three state-of-the-art temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis, and add novel extensions designed to handle variable-length inputs and learn robust spatial features We aggregate four publicly available datasets comprising 3,161 patients for pre-training, and show the performance of our model across multiple Alzheimers prediction tasks including diagnosis classification, conversion detection, and future conversion prediction",
    "type": "semantic",
    "chunk_id": "arxiv_1_chunk_1",
    "source_doc_id": "arxiv_1",
    "source_title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and\n  Adaptability Across Alzheimer's Prediction Tasks and Datasets",
    "source": "arxiv",
    "chunk_index": 1,
    "word_count": 63,
    "char_count": 488,
    "metadata": {
      "original_length": 1342,
      "cleaned_length": 1335,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Importantly, our SSL model implemented with temporal order prediction and contrastive learning outperforms supervised learning on six out of seven downstream tasks It demonstrates adaptability and generalizability across tasks and number of input images with varying time intervals, highlighting its capacity for robust performance across clinical applications We release our code and model publicly at https:github comemilykaczmarekSSL-AD",
    "type": "semantic",
    "chunk_id": "arxiv_1_chunk_2",
    "source_doc_id": "arxiv_1",
    "source_title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and\n  Adaptability Across Alzheimer's Prediction Tasks and Datasets",
    "source": "arxiv",
    "chunk_index": 2,
    "word_count": 57,
    "char_count": 439,
    "metadata": {
      "original_length": 1342,
      "cleaned_length": 1335,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Alzheimers disease is a progressive, neurodegenerative disorder that causes memory loss and cognitive decline While there has been extensive research in applying deep learning models to Alzheimers prediction tasks, these models remain limited by lack of available labeled data, poor generalization across datasets, and inflexibility to varying numbers of input scans and time intervals between scans",
    "type": "semantic",
    "chunk_id": "arxiv_2_chunk_0",
    "source_doc_id": "arxiv_2",
    "source_title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and\n  Adaptability Across Alzheimer's Prediction Tasks and Datasets",
    "source": "arxiv",
    "chunk_index": 0,
    "word_count": 56,
    "char_count": 399,
    "metadata": {
      "original_length": 1342,
      "cleaned_length": 1335,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "In this study, we adapt three state-of-the-art temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis, and add novel extensions designed to handle variable-length inputs and learn robust spatial features We aggregate four publicly available datasets comprising 3,161 patients for pre-training, and show the performance of our model across multiple Alzheimers prediction tasks including diagnosis classification, conversion detection, and future conversion prediction",
    "type": "semantic",
    "chunk_id": "arxiv_2_chunk_1",
    "source_doc_id": "arxiv_2",
    "source_title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and\n  Adaptability Across Alzheimer's Prediction Tasks and Datasets",
    "source": "arxiv",
    "chunk_index": 1,
    "word_count": 63,
    "char_count": 488,
    "metadata": {
      "original_length": 1342,
      "cleaned_length": 1335,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Importantly, our SSL model implemented with temporal order prediction and contrastive learning outperforms supervised learning on six out of seven downstream tasks It demonstrates adaptability and generalizability across tasks and number of input images with varying time intervals, highlighting its capacity for robust performance across clinical applications We release our code and model publicly at https:github comemilykaczmarekSSL-AD",
    "type": "semantic",
    "chunk_id": "arxiv_2_chunk_2",
    "source_doc_id": "arxiv_2",
    "source_title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and\n  Adaptability Across Alzheimer's Prediction Tasks and Datasets",
    "source": "arxiv",
    "chunk_index": 2,
    "word_count": 57,
    "char_count": 439,
    "metadata": {
      "original_length": 1342,
      "cleaned_length": 1335,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "Pretrained automatic speech recognition (ASR) models such as Whisper perform well but still need domain adaptation to handle unseen vocabulary and parlance In many real-world settings, collecting speech data is impractical, necessitating text-only adaptation We propose WhisTLE, a deeply supervised, text-only adaptation method for pretrained encoder-decoder ASR models",
    "type": "semantic",
    "chunk_id": "arxiv_3_chunk_0",
    "source_doc_id": "arxiv_3",
    "source_title": "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained\n  Speech Recognition Transformers",
    "source": "arxiv",
    "chunk_index": 0,
    "word_count": 48,
    "char_count": 369,
    "metadata": {
      "original_length": 871,
      "cleaned_length": 870,
      "chunking_strategy": "semantic"
    }
  },
  {
    "text": "WhisTLE trains a variational autoencoder (VAE) to model encoder outputs from text and fine-tunes the decoder using the learned text-to-latent encoder, optionally combined with text-to-speech (TTS) adaptation At inference, the original encoder is restored, incurring no extra runtime cost Across four out-of-domain datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by 12 3 relative to TTS-only adaptation and outperforms all non-WhisTLE baselines in 27 of 32 scenarios",
    "type": "semantic",
    "chunk_id": "arxiv_3_chunk_1",
    "source_doc_id": "arxiv_3",
    "source_title": "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained\n  Speech Recognition Transformers",
    "source": "arxiv",
    "chunk_index": 1,
    "word_count": 72,
    "char_count": 494,
    "metadata": {
      "original_length": 871,
      "cleaned_length": 870,
      "chunking_strategy": "semantic"
    }
  }
]