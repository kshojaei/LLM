{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Retrieval Systems\n",
        "\n",
        "In this notebook, we'll explore advanced retrieval techniques including hybrid search, reranking, and query expansion.\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will:\n",
        "1. Implement hybrid search combining dense and sparse retrieval\n",
        "2. Learn about reranking techniques to improve result quality\n",
        "3. Explore query expansion and reformulation strategies\n",
        "4. Understand the trade-offs between different retrieval methods\n",
        "5. Build a complete retrieval pipeline with multiple strategies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Let's import the libraries we need and set up our retrieval system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rank_bm25 not found. Installing...\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from rank-bm25) (1.26.4)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n",
            " Libraries imported successfully!\n",
            "üìÅ Data directory: /Users/scienceman/Desktop/LLM/data\n",
            "üìÑ Loading processed chunks from /Users/scienceman/Desktop/LLM/data/processed/all_chunks.json\n",
            " Loaded 22 chunks\n",
            "Libraries imported successfully!\n",
            "Loaded 22 chunks from previous notebook\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "import sys\n",
        "sys.path.append(str(Path.cwd().parent))\n",
        "\n",
        "# Import our modules\n",
        "try:\n",
        "    from src.retrieval.retrieval_system import RetrievalSystem, RetrievalConfig\n",
        "    from src.models.embedding_models import BGEEmbeddingModel, E5EmbeddingModel\n",
        "    from src.models.reranker_models import BGEReranker\n",
        "    from src.config import DATA_DIR\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Creating fallback implementations...\")\n",
        "    \n",
        "    # Fallback configuration\n",
        "    DATA_DIR = Path(\"data\")\n",
        "    \n",
        "    class RetrievalConfig:\n",
        "        def __init__(self):\n",
        "            self.top_k = 10\n",
        "            self.rerank_top_k = 5\n",
        "            self.similarity_threshold = 0.7\n",
        "            self.hybrid_alpha = 0.7\n",
        "            self.hybrid_beta = 0.3\n",
        "            self.use_reranking = True\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\" Libraries imported successfully!\")\n",
        "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
        "\n",
        "# Load sample data\n",
        "processed_dir = DATA_DIR / \"processed\"\n",
        "chunks_file = processed_dir / \"all_chunks.json\"\n",
        "\n",
        "if chunks_file.exists():\n",
        "    print(f\"üìÑ Loading processed chunks from {chunks_file}\")\n",
        "    with open(chunks_file, 'r', encoding='utf-8') as f:\n",
        "        all_chunks = json.load(f)\n",
        "    print(f\" Loaded {len(all_chunks)} chunks\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No processed chunks found. Creating sample data...\")\n",
        "    all_chunks = [\n",
        "        {\n",
        "            'id': 'chunk1',\n",
        "            'text': 'Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.',\n",
        "            'title': 'Machine Learning',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_1'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk2', \n",
        "            'text': 'Deep learning uses neural networks with multiple layers to process data and make predictions.',\n",
        "            'title': 'Deep Learning',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_2'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk3',\n",
        "            'text': 'Natural language processing helps computers understand, interpret, and generate human language.',\n",
        "            'title': 'NLP',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_3'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk4',\n",
        "            'text': 'Computer vision enables machines to interpret and understand visual information from the world.',\n",
        "            'title': 'Computer Vision',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_4'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk5',\n",
        "            'text': 'Reinforcement learning is a type of machine learning where agents learn through interaction with an environment.',\n",
        "            'title': 'Reinforcement Learning',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_5'\n",
        "        }\n",
        "    ]\n",
        "    print(f\" Created {len(all_chunks)} sample chunks\")\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# Load sample data\n",
        "chunks_file = DATA_DIR / \"processed\" / \"all_chunks.json\"\n",
        "if chunks_file.exists():\n",
        "    with open(chunks_file, 'r', encoding='utf-8') as f:\n",
        "        all_chunks = json.load(f)\n",
        "    print(f\"Loaded {len(all_chunks)} chunks from previous notebook\")\n",
        "else:\n",
        "    print(\"Creating sample data...\")\n",
        "    all_chunks = [\n",
        "        {\n",
        "            'id': 'chunk1',\n",
        "            'text': 'Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.',\n",
        "            'title': 'Machine Learning',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_1'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk2',\n",
        "            'text': 'Deep learning uses neural networks with multiple layers to process complex data patterns.',\n",
        "            'title': 'Deep Learning', \n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_2'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk3',\n",
        "            'text': 'Natural language processing is a field of AI that focuses on the interaction between computers and human language.',\n",
        "            'title': 'NLP',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_3'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk4',\n",
        "            'text': 'Computer vision is a field of artificial intelligence that trains computers to interpret and understand visual information.',\n",
        "            'title': 'Computer Vision',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_4'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk5',\n",
        "            'text': 'Reinforcement learning is a type of machine learning where agents learn to make decisions through trial and error.',\n",
        "            'title': 'Reinforcement Learning',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_5'\n",
        "        }\n",
        "    ]\n",
        "    print(f\"Created {len(all_chunks)} sample chunks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building Advanced Retrieval Systems\n",
        "\n",
        "Let's build a comprehensive retrieval system that combines multiple strategies for better results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Creating Advanced Retrieval System...\n",
            " Adding 22 documents to retrieval system...\n",
            "üî¢ Generating dense embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e936e30a6537401baab4be2717a12a7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Generating sparse embeddings (TF-IDF)...\n",
            " Retrieval system ready with 22 documents\n",
            "   Dense embeddings shape: (22, 384)\n",
            "   Sparse embeddings shape: (22, 446)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries for our retrieval system\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "class AdvancedRetrievalSystem:\n",
        "    \"\"\"Advanced retrieval system with multiple strategies.\"\"\"\n",
        "    \n",
        "    def __init__(self, embedding_model='all-MiniLM-L6-v2'):\n",
        "        \"\"\"Initialize the retrieval system.\"\"\"\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "        \n",
        "        # Storage for documents and embeddings\n",
        "        self.documents = []\n",
        "        self.metadata = []\n",
        "        self.dense_embeddings = None\n",
        "        self.sparse_embeddings = None\n",
        "        self.tfidf_matrix = None\n",
        "        \n",
        "    def add_documents(self, documents, metadata=None):\n",
        "        \"\"\"Add documents to the retrieval system.\"\"\"\n",
        "        print(f\" Adding {len(documents)} documents to retrieval system...\")\n",
        "        \n",
        "        self.documents = documents\n",
        "        self.metadata = metadata or [{}] * len(documents)\n",
        "        \n",
        "        # Generate dense embeddings\n",
        "        print(\"üî¢ Generating dense embeddings...\")\n",
        "        self.dense_embeddings = self.embedding_model.encode(documents, show_progress_bar=True)\n",
        "        \n",
        "        # Generate sparse embeddings (TF-IDF)\n",
        "        print(\" Generating sparse embeddings (TF-IDF)...\")\n",
        "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(documents)\n",
        "        \n",
        "        print(f\" Retrieval system ready with {len(documents)} documents\")\n",
        "        print(f\"   Dense embeddings shape: {self.dense_embeddings.shape}\")\n",
        "        print(f\"   Sparse embeddings shape: {self.tfidf_matrix.shape}\")\n",
        "    \n",
        "    def dense_search(self, query, top_k=10):\n",
        "        \"\"\"Perform dense vector search.\"\"\"\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.dense_embeddings)[0]\n",
        "        \n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "        \n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            results.append({\n",
        "                'document': self.documents[idx],\n",
        "                'similarity': similarities[idx],\n",
        "                'metadata': self.metadata[idx],\n",
        "                'index': idx,\n",
        "                'method': 'dense'\n",
        "            })\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def sparse_search(self, query, top_k=10):\n",
        "        \"\"\"Perform sparse vector search (TF-IDF).\"\"\"\n",
        "        query_vector = self.tfidf_vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]\n",
        "        \n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "        \n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            results.append({\n",
        "                'document': self.documents[idx],\n",
        "                'similarity': similarities[idx],\n",
        "                'metadata': self.metadata[idx],\n",
        "                'index': idx,\n",
        "                'method': 'sparse'\n",
        "            })\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def hybrid_search(self, query, top_k=10, alpha=0.7, beta=0.3):\n",
        "        \"\"\"Perform hybrid search combining dense and sparse methods.\"\"\"\n",
        "        # Get results from both methods\n",
        "        dense_results = self.dense_search(query, top_k=top_k*2)\n",
        "        sparse_results = self.sparse_search(query, top_k=top_k*2)\n",
        "        \n",
        "        # Create score dictionary\n",
        "        scores = {}\n",
        "        \n",
        "        # Add dense scores\n",
        "        for result in dense_results:\n",
        "            idx = result['index']\n",
        "            scores[idx] = scores.get(idx, 0) + alpha * result['similarity']\n",
        "        \n",
        "        # Add sparse scores\n",
        "        for result in sparse_results:\n",
        "            idx = result['index']\n",
        "            scores[idx] = scores.get(idx, 0) + beta * result['similarity']\n",
        "        \n",
        "        # Sort by combined score\n",
        "        sorted_indices = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)[:top_k]\n",
        "        \n",
        "        # Create final results\n",
        "        results = []\n",
        "        for idx in sorted_indices:\n",
        "            results.append({\n",
        "                'document': self.documents[idx],\n",
        "                'similarity': scores[idx],\n",
        "                'metadata': self.metadata[idx],\n",
        "                'index': idx,\n",
        "                'method': 'hybrid',\n",
        "                'dense_score': alpha * dense_results[0]['similarity'] if any(r['index'] == idx for r in dense_results) else 0,\n",
        "                'sparse_score': beta * sparse_results[0]['similarity'] if any(r['index'] == idx for r in sparse_results) else 0\n",
        "            })\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def query_expansion(self, query, expansion_terms=3):\n",
        "        \"\"\"Expand query with related terms.\"\"\"\n",
        "        # Simple query expansion using TF-IDF\n",
        "        query_terms = query.lower().split()\n",
        "        \n",
        "        # Find documents that contain query terms\n",
        "        expanded_terms = set(query_terms)\n",
        "        \n",
        "        for i, doc in enumerate(self.documents):\n",
        "            doc_terms = doc.lower().split()\n",
        "            if any(term in doc_terms for term in query_terms):\n",
        "                # Add frequent terms from this document\n",
        "                term_counts = Counter(doc_terms)\n",
        "                for term, count in term_counts.most_common(5):\n",
        "                    if term not in query_terms and len(term) > 3:\n",
        "                        expanded_terms.add(term)\n",
        "                        if len(expanded_terms) >= len(query_terms) + expansion_terms:\n",
        "                            break\n",
        "            if len(expanded_terms) >= len(query_terms) + expansion_terms:\n",
        "                break\n",
        "        \n",
        "        expanded_query = ' '.join(expanded_terms)\n",
        "        return expanded_query\n",
        "    \n",
        "    def search_with_expansion(self, query, top_k=10, use_expansion=True):\n",
        "        \"\"\"Search with optional query expansion.\"\"\"\n",
        "        if use_expansion:\n",
        "            expanded_query = self.query_expansion(query)\n",
        "            print(f\"üîç Original query: '{query}'\")\n",
        "            print(f\"üîç Expanded query: '{expanded_query}'\")\n",
        "            return self.hybrid_search(expanded_query, top_k)\n",
        "        else:\n",
        "            return self.hybrid_search(query, top_k)\n",
        "\n",
        "# Create our advanced retrieval system\n",
        "print(\" Creating Advanced Retrieval System...\")\n",
        "retrieval_system = AdvancedRetrievalSystem()\n",
        "\n",
        "# Add documents\n",
        "documents = [chunk['text'] for chunk in all_chunks]\n",
        "metadata = [{'title': chunk['source_title'], 'source': chunk['source']} for chunk in all_chunks]\n",
        "\n",
        "retrieval_system.add_documents(documents, metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Retrieval Method Comparison\n",
        "\n",
        "Let's compare different retrieval methods side by side to understand their strengths and weaknesses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_retrieval_methods(query, top_k=5):\n",
        "    \"\"\"Compare different retrieval methods for a given query.\"\"\"\n",
        "    print(f\"üîç Query: '{query}'\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Dense search\n",
        "    print(\"\\n DENSE SEARCH (Semantic Similarity)\")\n",
        "    print(\"-\" * 50)\n",
        "    dense_results = retrieval_system.dense_search(query, top_k)\n",
        "    for i, result in enumerate(dense_results):\n",
        "        print(f\"{i+1}. [{result['similarity']:.3f}] {result['metadata']['title']}\")\n",
        "        print(f\"   {result['document'][:100]}...\")\n",
        "    \n",
        "    # Sparse search\n",
        "    print(\"\\n SPARSE SEARCH (Keyword Matching)\")\n",
        "    print(\"-\" * 50)\n",
        "    sparse_results = retrieval_system.sparse_search(query, top_k)\n",
        "    for i, result in enumerate(sparse_results):\n",
        "        print(f\"{i+1}. [{result['similarity']:.3f}] {result['metadata']['title']}\")\n",
        "        print(f\"   {result['document'][:100]}...\")\n",
        "    \n",
        "    # Hybrid search\n",
        "    print(\"\\nüîÑ HYBRID SEARCH (Combined)\")\n",
        "    print(\"-\" * 50)\n",
        "    hybrid_results = retrieval_system.hybrid_search(query, top_k)\n",
        "    for i, result in enumerate(hybrid_results):\n",
        "        print(f\"{i+1}. [{result['similarity']:.3f}] {result['metadata']['title']}\")\n",
        "        print(f\"   {result['document'][:100]}...\")\n",
        "    \n",
        "    # Query expansion\n",
        "    print(\"\\n QUERY EXPANSION + HYBRID\")\n",
        "    print(\"-\" * 50)\n",
        "    expanded_results = retrieval_system.search_with_expansion(query, top_k, use_expansion=True)\n",
        "    for i, result in enumerate(expanded_results):\n",
        "        print(f\"{i+1}. [{result['similarity']:.3f}] {result['metadata']['title']}\")\n",
        "        print(f\"   {result['document'][:100]}...\")\n",
        "    \n",
        "    return {\n",
        "        'dense': dense_results,\n",
        "        'sparse': sparse_results,\n",
        "        'hybrid': hybrid_results,\n",
        "        'expanded': expanded_results\n",
        "    }\n",
        "\n",
        "# Test with different types of queries\n",
        "test_queries = [\n",
        "    \"machine learning algorithms\",\n",
        "    \"neural networks\",\n",
        "    \"artificial intelligence applications\",\n",
        "    \"data processing techniques\"\n",
        "]\n",
        "\n",
        "print(\" COMPREHENSIVE RETRIEVAL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for query in test_queries:\n",
        "    results = compare_retrieval_methods(query)\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Analysis and Visualization\n",
        "\n",
        "Let's analyze the performance characteristics of different retrieval methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance benchmarking\n",
        "import time\n",
        "\n",
        "def benchmark_retrieval_methods(queries, iterations=3):\n",
        "    \"\"\"Benchmark different retrieval methods.\"\"\"\n",
        "    methods = ['dense', 'sparse', 'hybrid', 'expanded']\n",
        "    results = {method: [] for method in methods}\n",
        "    \n",
        "    for _ in range(iterations):\n",
        "        for query in queries:\n",
        "            # Dense search\n",
        "            start = time.time()\n",
        "            retrieval_system.dense_search(query, top_k=5)\n",
        "            results['dense'].append(time.time() - start)\n",
        "            \n",
        "            # Sparse search\n",
        "            start = time.time()\n",
        "            retrieval_system.sparse_search(query, top_k=5)\n",
        "            results['sparse'].append(time.time() - start)\n",
        "            \n",
        "            # Hybrid search\n",
        "            start = time.time()\n",
        "            retrieval_system.hybrid_search(query, top_k=5)\n",
        "            results['hybrid'].append(time.time() - start)\n",
        "            \n",
        "            # Expanded search\n",
        "            start = time.time()\n",
        "            retrieval_system.search_with_expansion(query, top_k=5, use_expansion=True)\n",
        "            results['expanded'].append(time.time() - start)\n",
        "    \n",
        "    # Calculate statistics\n",
        "    stats = {}\n",
        "    for method, times in results.items():\n",
        "        stats[method] = {\n",
        "            'mean': np.mean(times),\n",
        "            'std': np.std(times),\n",
        "            'min': np.min(times),\n",
        "            'max': np.max(times)\n",
        "        }\n",
        "    \n",
        "    return stats\n",
        "\n",
        "# Benchmark performance\n",
        "print(\" PERFORMANCE BENCHMARKING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "benchmark_queries = [\n",
        "    \"machine learning\",\n",
        "    \"neural networks\",\n",
        "    \"artificial intelligence\",\n",
        "    \"data science\"\n",
        "]\n",
        "\n",
        "performance_stats = benchmark_retrieval_methods(benchmark_queries)\n",
        "\n",
        "for method, stats in performance_stats.items():\n",
        "    print(f\"\\n{method.upper()} SEARCH:\")\n",
        "    print(f\"  Mean time: {stats['mean']:.4f}s\")\n",
        "    print(f\"  Std dev: {stats['std']:.4f}s\")\n",
        "    print(f\"  Min time: {stats['min']:.4f}s\")\n",
        "    print(f\"  Max time: {stats['max']:.4f}s\")\n",
        "\n",
        "# Create performance visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Retrieval Method Performance Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Bar chart of mean times\n",
        "methods = list(performance_stats.keys())\n",
        "mean_times = [performance_stats[method]['mean'] for method in methods]\n",
        "\n",
        "axes[0,0].bar(methods, mean_times, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "axes[0,0].set_title('Mean Search Time by Method')\n",
        "axes[0,0].set_ylabel('Time (seconds)')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Box plot of time distributions\n",
        "all_times = []\n",
        "labels = []\n",
        "for method, stats in performance_stats.items():\n",
        "    # Get actual times for box plot\n",
        "    method_times = []\n",
        "    for _ in range(3):  # iterations\n",
        "        for query in benchmark_queries:\n",
        "            start = time.time()\n",
        "            if method == 'dense':\n",
        "                retrieval_system.dense_search(query, top_k=5)\n",
        "            elif method == 'sparse':\n",
        "                retrieval_system.sparse_search(query, top_k=5)\n",
        "            elif method == 'hybrid':\n",
        "                retrieval_system.hybrid_search(query, top_k=5)\n",
        "            elif method == 'expanded':\n",
        "                retrieval_system.search_with_expansion(query, top_k=5, use_expansion=True)\n",
        "            method_times.append(time.time() - start)\n",
        "    all_times.append(method_times)\n",
        "    labels.append(method)\n",
        "\n",
        "axes[0,1].boxplot(all_times, labels=labels)\n",
        "axes[0,1].set_title('Time Distribution by Method')\n",
        "axes[0,1].set_ylabel('Time (seconds)')\n",
        "axes[0,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Memory usage analysis\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "def get_memory_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss / 1024 / 1024  # MB\n",
        "\n",
        "memory_usage = []\n",
        "method_names = []\n",
        "\n",
        "for method in methods:\n",
        "    memory_before = get_memory_usage()\n",
        "    \n",
        "    # Perform search\n",
        "    for query in benchmark_queries:\n",
        "        if method == 'dense':\n",
        "            retrieval_system.dense_search(query, top_k=5)\n",
        "        elif method == 'sparse':\n",
        "            retrieval_system.sparse_search(query, top_k=5)\n",
        "        elif method == 'hybrid':\n",
        "            retrieval_system.hybrid_search(query, top_k=5)\n",
        "        elif method == 'expanded':\n",
        "            retrieval_system.search_with_expansion(query, top_k=5, use_expansion=True)\n",
        "    \n",
        "    memory_after = get_memory_usage()\n",
        "    memory_usage.append(memory_after - memory_before)\n",
        "    method_names.append(method)\n",
        "\n",
        "axes[1,0].bar(method_names, memory_usage, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "axes[1,0].set_title('Memory Usage by Method')\n",
        "axes[1,0].set_ylabel('Memory Increase (MB)')\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Accuracy comparison (simulated)\n",
        "# In a real scenario, you'd have ground truth labels\n",
        "accuracy_scores = {\n",
        "    'dense': 0.85,\n",
        "    'sparse': 0.72,\n",
        "    'hybrid': 0.91,\n",
        "    'expanded': 0.88\n",
        "}\n",
        "\n",
        "axes[1,1].bar(method_names, [accuracy_scores[method] for method in method_names], \n",
        "             color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "axes[1,1].set_title('Accuracy Comparison (Simulated)')\n",
        "axes[1,1].set_ylabel('Accuracy Score')\n",
        "axes[1,1].set_ylim(0, 1)\n",
        "axes[1,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary insights\n",
        "print(f\"\\n PERFORMANCE INSIGHTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üèÜ Fastest method: {min(performance_stats.keys(), key=lambda x: performance_stats[x]['mean'])}\")\n",
        "print(f\"üèÜ Most accurate: hybrid (simulated)\")\n",
        "print(f\"üèÜ Most memory efficient: {min(performance_stats.keys(), key=lambda x: memory_usage[methods.index(x)])}\")\n",
        "print(f\"üèÜ Best overall: hybrid (good balance of speed and accuracy)\")\n",
        "\n",
        "# Hybrid search parameter tuning\n",
        "print(f\"\\n HYBRID SEARCH PARAMETER TUNING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "alpha_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "beta_values = [0.9, 0.7, 0.5, 0.3, 0.1]\n",
        "\n",
        "tuning_results = []\n",
        "for alpha, beta in zip(alpha_values, beta_values):\n",
        "    start = time.time()\n",
        "    retrieval_system.hybrid_search(\"machine learning\", top_k=5, alpha=alpha, beta=beta)\n",
        "    search_time = time.time() - start\n",
        "    tuning_results.append({\n",
        "        'alpha': alpha,\n",
        "        'beta': beta,\n",
        "        'time': search_time\n",
        "    })\n",
        "\n",
        "print(\"Alpha | Beta | Time\")\n",
        "print(\"-\" * 20)\n",
        "for result in tuning_results:\n",
        "    print(f\"{result['alpha']:5.1f} | {result['beta']:4.1f} | {result['time']:.4f}s\")\n",
        "\n",
        "# Plot parameter tuning results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(alpha_values, [r['time'] for r in tuning_results], 'o-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Alpha (Dense Weight)')\n",
        "plt.ylabel('Search Time (seconds)')\n",
        "plt.title('Hybrid Search Parameter Tuning')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data.collect_data:Data collector initialized. Output directory: /Users/scienceman/Desktop/LLM/data/raw\n",
            "INFO:src.data.collect_data:Collecting ArXiv data...\n",
            "INFO:src.data.collect_data:Fetching real ArXiv data using ArXiv API...\n",
            "INFO:src.data.collect_data:Collected: FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning\n",
            "  Dataset and Comprehensive Benchmark\n",
            "INFO:src.data.collect_data:Collected: ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable\n",
            "  Orthogonal Butterfly Transforms\n",
            "INFO:src.data.collect_data:Collected: ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable\n",
            "  Orthogonal Butterfly Transforms\n",
            "INFO:src.data.collect_data:Collected: SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning\n",
            "INFO:src.data.collect_data:Successfully collected 4 ArXiv papers\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected 4 ArXiv papers\n",
            "ArXiv sample structure: 4 papers\n",
            "First paper title: FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning\n",
            "  Dataset and Comprehensive Benchmark\n",
            "First paper abstract length: 1595 characters\n"
          ]
        }
      ],
      "source": [
        "# Use our DataCollector instead of direct load_dataset\n",
        "from src.data.collect_data import DataCollector\n",
        "collector = DataCollector()\n",
        "arxiv_sample_data = collector.collect_arxiv_data(max_documents=5)\n",
        "print(f'Collected {len(arxiv_sample_data)} ArXiv papers')\n",
        "\n",
        "# Convert to the format expected by the rest of the notebook\n",
        "arxiv_sample = []\n",
        "for paper in arxiv_sample_data:\n",
        "    arxiv_sample.append({\n",
        "        'title': paper['title'],\n",
        "        'abstract': paper['abstract']\n",
        "    })\n",
        "\n",
        "print(f'ArXiv sample structure: {len(arxiv_sample)} papers')\n",
        "if arxiv_sample:\n",
        "    print(f'First paper title: {arxiv_sample[0][\"title\"]}')\n",
        "    print(f'First paper abstract length: {len(arxiv_sample[0][\"abstract\"])} characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a Complete Retrieval System\n",
        "\n",
        "Let's create a comprehensive retrieval system with multiple strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.embedding_models:Loading BGE model: BAAI/bge-base-en-v1.5\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating retrieval systems...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9ea7a1e07a744ceb0ba22e369b14f0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2de1b36cb37d4c5c87cba2e59e16606b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f2611d1f0f8492bb65b658fe3e4c7db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18eacfb73c164e748b239f7b605ba375",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f39dafd3d0f49cd9d28ce2132229192",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "023d562758c64d13bbf719e5cd883ace",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0fa1f4ecc2e4f36a367176ef43f2688",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "013600873dcd4e12b897f0b652be1cc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "143b465cff224efcadc871c2b7253493",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "751a440ea42c419d93a98cbc4796c973",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0d45108007547e0b9a496e5dca4ac64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.embedding_models:BGE model loaded successfully\n",
            "INFO:src.models.embedding_models:Loading BGE model: BAAI/bge-base-en-v1.5\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
            "INFO:src.models.embedding_models:BGE model loaded successfully\n",
            "INFO:src.models.reranker_models:Loading BGE reranker: BAAI/bge-reranker-large\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0b11bd03a9f49778ce511b97da7a904",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "923b878748f24e17aa1ca58ba1c18d7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68b5d90941c340d2a170811d80dce835",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f7d3e2b09de47c99b7d5f80f96c22e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33adaccacbaa427784e24f1beb2ca0d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be901fbdd21b42b58118aaf23f790300",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.reranker_models:BGE reranker loaded successfully\n",
            "INFO:src.models.embedding_models:Loading BGE model: BAAI/bge-base-en-v1.5\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
            "INFO:src.models.embedding_models:BGE model loaded successfully\n",
            "INFO:src.models.reranker_models:Loading BGE reranker: BAAI/bge-reranker-large\n",
            "INFO:src.models.reranker_models:BGE reranker loaded successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding documents to retrieval systems...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8597d2f4d9004983884ef923383852f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "020dbc4957fe430cb66564295f9e6133",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e10c7d20dd384e058615069ab31e6f8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecc0d00a15a1430782a83a92dd6bf91c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "942b04bc39f748718e3a9c8f43d5cf03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0214b648b4ea4894a55e96141d658371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 22 documents to each retrieval system\n",
            "Retrieval systems ready!\n"
          ]
        }
      ],
      "source": [
        "# Create retrieval system with different configurations\n",
        "print(\"Creating retrieval systems...\")\n",
        "\n",
        "# Configuration 1: Basic retrieval\n",
        "basic_config = RetrievalConfig(\n",
        "    top_k=5,\n",
        "    rerank_top_k=3,\n",
        "    use_reranking=False,\n",
        "    similarity_threshold=0.5\n",
        ")\n",
        "\n",
        "# Configuration 2: With reranking\n",
        "rerank_config = RetrievalConfig(\n",
        "    top_k=10,\n",
        "    rerank_top_k=5,\n",
        "    use_reranking=True,\n",
        "    similarity_threshold=0.3\n",
        ")\n",
        "\n",
        "# Configuration 3: Hybrid search\n",
        "hybrid_config = RetrievalConfig(\n",
        "    top_k=10,\n",
        "    rerank_top_k=5,\n",
        "    use_reranking=True,\n",
        "    similarity_threshold=0.3,\n",
        "    hybrid_alpha=0.7,\n",
        "    hybrid_beta=0.3\n",
        ")\n",
        "\n",
        "# Create retrieval systems\n",
        "basic_retrieval = RetrievalSystem(basic_config)\n",
        "rerank_retrieval = RetrievalSystem(rerank_config)\n",
        "hybrid_retrieval = RetrievalSystem(hybrid_config)\n",
        "\n",
        "# Add documents to all systems\n",
        "print(\"Adding documents to retrieval systems...\")\n",
        "basic_retrieval.add_documents(all_chunks)\n",
        "rerank_retrieval.add_documents(all_chunks)\n",
        "hybrid_retrieval.add_documents(all_chunks)\n",
        "\n",
        "print(f\"Added {len(all_chunks)} documents to each retrieval system\")\n",
        "print(\"Retrieval systems ready!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
