{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Integration and Prompt Engineering\n",
        "\n",
        "In this notebook, we'll learn how to integrate language models with our retrieval system and master prompt engineering techniques.\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will:\n",
        "1. Integrate different LLMs with the retrieval system\n",
        "2. Master prompt engineering for RAG applications\n",
        "3. Learn about context management and token limits\n",
        "4. Implement streaming responses for better user experience\n",
        "5. Understand the trade-offs between different LLM models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Let's import the libraries we need for LLM integration and prompt engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "\n",
        "# Add project root to path\n",
        "import sys\n",
        "sys.path.append(str(Path.cwd().parent))\n",
        "\n",
        "# Import our modules\n",
        "from src.models.llm_models import RAGGenerator, PromptTemplate, LlamaModel, MistralModel\n",
        "from src.retrieval.retrieval_system import RetrievalSystem, RetrievalConfig\n",
        "from src.config import DATA_DIR\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# Load sample data\n",
        "chunks_file = DATA_DIR / \"processed\" / \"all_chunks.json\"\n",
        "if chunks_file.exists():\n",
        "    with open(chunks_file, 'r', encoding='utf-8') as f:\n",
        "        all_chunks = json.load(f)\n",
        "    print(f\"Loaded {len(all_chunks)} chunks\")\n",
        "else:\n",
        "    print(\"Creating sample data...\")\n",
        "    all_chunks = [\n",
        "        {\n",
        "            'id': 'chunk1',\n",
        "            'text': 'Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.',\n",
        "            'title': 'Machine Learning',\n",
        "            'source': 'wikipedia',\n",
        "            'chunk_id': 'chunk_1'\n",
        "        },\n",
        "        {\n",
        "            'id': 'chunk2',\n",
        "            'text': 'Deep learning uses neural networks with multiple layers to process complex data patterns.',\n",
        "            'title': 'Deep Learning',\n",
        "            'source': 'wikipedia', \n",
        "            'chunk_id': 'chunk_2'\n",
        "        }\n",
        "    ]\n",
        "    print(f\"Created {len(all_chunks)} sample chunks\")\n",
        "\n",
        "# Create a simple retrieval system for demonstration\n",
        "retrieval_config = RetrievalConfig(top_k=3, use_reranking=False)\n",
        "retrieval_system = RetrievalSystem(retrieval_config)\n",
        "retrieval_system.add_documents(all_chunks)\n",
        "print(\"Retrieval system ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
